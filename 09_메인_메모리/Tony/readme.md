# Part 4. 메모리 관리(Memory Management)

- 컴퓨터 -> 프로그램 수행
- 프로그램 -> 메모리에 적재
- 최신 컴퓨터 시스템은 시스템 실행 중에 여러 프로세스를 메모리에 유지한다
  - 다양한 접근 방식을 반영하는 많은 `메모리 관리 기법`이 있으며 각 알고리즘의 효과는 상황에 따라 다르다
  - 시스템을 위한 메모리 관리 기법의 선택은 많은 요소, 특히 시스템의 하드웨어 설계에 따라 달라진다
  - 거의 모든 알고리즘은 일정 형태의 하드웨어 지원이 필요하다

# 9. 메인 메모리(Main Memory)

- 5장에서는 일련의 프로레스가 CPU를 공유하는 방법을 보여주었다
  - CPU 스케줄링의 결과로 CPU 이용률과 사용자에 제공하는 컴퓨터 응답속도를 모두 향상할 수 있었다
  - 그러나 이러한 성능향상을 실현하려면 많은 `프로세스를 메모리에 유지`해야 한다
  - 즉, `메모리를 공유`해야 한다
- 메모리 관리 알고리즘 : 베어머신, 페이징, ...
- 메모리 관리 방법의 선택은 하드웨어 설계에 따라 달라진다
- 시스템에서 하드웨어와 운영체제 메모리 관리를 밀접하게 통합해야 한다

#### 이 장의 목표

- 논리 주소와 물리 주소의 차이점과 주소를 변환할 때 MMU(메모리 관리 장치)의 역할을 설명한다
- 메모리를 연속적으로 할당하기 위해 최초, 최적 및 최악 접합 전략을 적용한다
- 내부 및 외부 단편화의 차이점을 설명한다
- TLB(translation look-aside buffer)가 포함된 페이징 시스템에서 논리 주소를 물리 주소로 변환한다
- 계층적 페이징, 해시 페이징 및 역 페이지 테이블을 설명한다
- IA-32, x86-64, ARMv8 아키텍처의 주소 변환에 관해 설명한다

## 9.1 배경(Background)

- 전형적인 명령어 실행
  - 메모리로 부터 명령어를 가져온다
  - 명령어를 해독, 메모리에서 피연산자(operand)를 가져와 피연산자에 대해 명령어를 실행한 후
  - 계산 결과를 메모리에 다시 저장한다
- 메모리는 주소에 지시한 대로 읽기, 쓰기만 할 뿐
  - 이 주소들이 어떻게 생성되었는지 혹은 그 주소가 가리키는 내용이 무엇인지를 모른다
- 이번 챕터에서 다룰 주요 내용
  - 논리 주소
  - 물리 주소
  - ('코드'와 '공유 라이브러리'의) 동적 적재와 연결

### 9.1.1 기본 하드웨어(Basic hardware)

- CPU가 직접 접근할 수 있는 유일한 범용 장치 : 메인 메모리, 각 처리 코어에 내장된 레지스터들
- CPU 코어에 내장된 레지스터들은 일반적으로 1클록 내에 접근이 가능하다
- 그러나 메모리 버스를 통해 전송되는 메인 메모리의 경우 앞에서 언급했던 상황과는 다르다
  - 메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱이 소요되며,
  - 이 경우 CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연되는(stall) 현상이 발생하게 된다
    - 메모리가 스톨되는 동안 다중 스레드 코어가 스톨 된 하드웨어 스레드에서 다른 하드웨어 스레드로 전호나할 수 있다(5.5.2절 참고)
- 메인 메모리의 접근이 빈번하게 일어나는 경우에
  - CPU와 메인 메모리 사이에 `캐시 메모리`를 두어 메인 메모리의 접근을 최소화할 수 있다
- 그리고 올바른 동작을 보장해야만 한다
  - 시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐만 아니라
  - 사용자 프로그램 사이도 서로 보호해야 한다
- 운영체제가 CPU와 메모리간의 접근 중에 개입하게 되면 성능이 떨어지기 때문에 이러한 `보호 기법`은 반드시 `하드웨어가 지원`하여야 한다
- 각 프로세스가 독립적인 메모리 공간을 가지도록 보장해야 한다
  - 개별적인 `프로세스별 메모리 공간`은 서로를 보호하고 병행 실행을 위해 여러 프로세스가 메모리에 적재되게 하는 것이 필수적이다
- 메모릴 공간을 분리하기 위해 특정 프로세스만 접근할 수 있는 합법적인(legal) 메모리 주소 영역을 설정하고, 프로세스가 합법적인 영역만을 접근하도록 하는 것이 필요하다
- 특권 명령 - 오직 커널 모드에서만 수행 - 운영체제만 커널 모드에서 수행
  - 운영체제만 레지스터들의 값을 변경할 수 있도록 허가해 줌으로써, 사용자 프로그램이 레지스터의 내용을 변경하는 것을 막는다

### 9.1.2 주소의 할당(Address Biding)

- 프로그램은 원래 이진 실행 파일 형태로 디스크에 저장되어 있다

  - 실행하려면 프로그램을 메모리로 가져와서 프로세스 문맥 내에 배치해야 한다
  - 이 시점에 가용한 CPU에서 실행할 수 있게 된다
  - 프로세스가 실행되면 메모리에서 명령 및 데이터에 엑세스 한다
  - 결국 프로세스가 종료되고 다른 프로세스에서 사용하기 위해 메모리가 회수된다

- 대부분의 사용자 프로그램은 그림 9.3과 같이 여러 단계를 거쳐 실행되기 때문에 이들 단계를 거치는 동안 주소들은 여러 가지 다른 표현 방식을 거치게 된다(메모리 주소 공간에서 명령어와 데이터의 바인딩)

  - 컴파일 시간 바인딩
    - 소스 프로그램
    - 컴파일러
    - 오브젝트 파일
  - 적재 시간 바인딩
    - 링커(<- 다른 오브젝트 파일)
    - 실행 파일
    - 로더
  - 실행 시간(런 타임) 바인딩
    - 메모리의 프로그램(<- 동적으로 링크되는 라이브러리)

- 이 장의 주요 요점은 컴퓨터 시스템에서 여러 가지 바인딩을 어떻게 효과적으로 구현할 수 있는가이며, 이를 위해 하드웨어 지원에 대해 언급하는 것이다

### 9.1.3 논리 대 물리 주소 공간(Logical vs. Physical Address Spaces)

- 논리 주소(logical address) : CPU가 생성하는 주소
  - 물리주소에 적재되기 전 논리주소 : 가상 주소(virtual address)
  - 이 책에서는 논리 주소와 가상 주소를 같은 의미로 사용
- 물리 주소(physical address) : 메모리가 취급하게 되는 주소

  - 메모리 주소 레지스터(MAR)에 주어지는 주소

- 프로그램 실행 중에 가상 주소(논리 주소)를 물리 주소로 바꿔야 하는데 이 변환(mapping) 작업은 하드웨어 장치인 메모리 관리 장치(Memory Management Unit, MMU)에 의해 실행된다

- 기준 레지스터 ~= 재배치(relocation) 레지스터

### 9.1.4 동적 적재(Dynamic Loading)

- 메모리 공간의 더 효율적 이용을 위해서는 동적 적재(dynamic loading)를 해야 한다
- 동적 적재에서 각 루틴은 실제 호출되기 전까찌는 메모리에 올라오지 않고 `재배치 가능한 상태로 디스크에서 대기`하고 있다
- 동적적재 과정
  - 메인 프로그램이 메모리에 올라와서 실행
  - 동적 적재할 루틴이 메모리에 적재됐는지를 조사
  - 동적 적재할 루틴이 메모리에 없으면 메모리에 적재

### 9.1.5 동적 연결 및 공유 라이브러리(Dynamic Linking and Shared Libraries)

- 동적 연결 라이브러리(DLL)은 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리이다
- 어떤 운영체제는 정적 연결만을 지원한다
  - 정적 연결 : 라이브러리가 해당 프로그램의 이진 프로그램 이미지(image)에 끼어 들어가게 된다
  - 동적 연결 : 연결(linking)이 실행 시기까지 미루어지는 것
    - (동적 적재의 개념과 유사) 동적 적재 : 로딩(loading)이 실행 시 까지 미루어짐
- DLL의 장점
  - 실행 가능 이미지 크기 감소, 메모리 낭비를 줄임
  - 라이브러리를 여러 프로세스 간에 공유할 수 있어 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있다
- DLL은 공유 라이브러리라고도 하며 Windows 및 Linux시스템에서 광범위하게 사용된다
- 동적 연결 라이브러리는 라이브러리 갱신으로 확장할 수 있다
  - 어느 때나 새로운 버전으로 교체될 수 있고, 그렇게 되면 그 라이브러리를 사용하는 모든 프로그램은 자동으로 이 새로운 라이브러리 버전을 사용하게 될 것이다

## 9.2 연속 메모리 할당(Contiguous Memory Allocation)

- 메인 메모리는 여러 사용자 프로세스도 수용해야 하기 때문에 각 영역은 각각 목적에 맞도록 효율적으로 관리되어야 한다
- 메모리는 두 개의 부분으로 나누어진다
  - 운영체제를 위한 것
  - 사용자 프로세스를 위한 것

### 9.2.1 메모리 보호(Memory Protection)

- 프로세스가 자신이 소유하지 않은 메모리를 접근 할 수 없게 강제할 수 있다
  - 상한 레지스터, 재배치 레지스터, 메모리 관리 장치(MMU)를 사용하여 메모리 보호를 구현할 수 있다

### 9.2.2 메모리 할당(Memory Allocation)

- 최초 적합(first-fit) : 가장 먼저 발견되는 충분한 공간에 할당
- 최적 적합(best-fit) : 할당할 공간이 가장 적은 곳에 할당
- 최악 적합(worst-fit) : 할당할 공간이 가장 많은 곳에 할당

### 9.2.3 단편화

- 9.2.2의 메모리 할당 전략은 (최초 적합과 최적 적합 전략) 모두 외부 단편화로 인해 어려움을 겪는다
- 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 어떤 가용공간은 너무 작은 조각이 되어버러니다
  - 작은 가용공간을 합쳐 하나의 큰 가용공간을 만들면 여러 개의 프로세스를 실행 시킬 수 있다
- 외부 단편화 문제를 해결할 수 있는 좋은 방법 : 페이징
  - 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법

## 9.3 페이징(Paging)

- 페이징은 운영체제와 컴퓨터 하드웨어 간의 협력을 통해 구현된다

### 9.3.1 기본 방법(Basic Method)

- 물리 메모리는 프레임(frame)이라 불리는 같은 크기 블록으로 나누어진다
- CPU에서 나오는 모든 `주소`는 `페이지 번호(p)`와 `페이지 오프셋(d: offset)`, 두 개의 부분으로 나누어진다
- CPU에 의해 생성된 논리 주소를 물리 주소로 변환하기 위해 MMU가 취한 단계
  - 1. 페이지 번호 p를 추출하여 페이지 테이블의 인덱스로 사용한다
  - 2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다
  - 3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다
- 페이징은 일종의 동적 재배치이다
- 페이징을 사용하는 것은 각 메모리 프레임마다 하나씩 기준(또는 재배치) 레지스터를 테이블로 유지하는 것과 유사하다
- 페이징 기법을 사용하면 외부 단편화가 발생하지 않는다
  - 모든 놀고 있는 프레임이 프로세스에 할당될 수 있기 때문이다
- 그러나 내부 단편화는 발생한다
  - 할당은 할상 프레임의 정수배로 할당되기 때문이다
- 디스크 입장에서는 페이지의 크기가 클 수록 효율적이다(11장 참조)
  - 프레임이 작을수록 페이지 테이블의 크기가 커진다
- 프레임의 일반적인 추세는 페이지 크기가 프로세스, 자료, 그리고 메인 메모리가 커짐에 따라 함께 커져왔다
  - 현재는 보통 페이지 크기가 4KB 또는 8KB이다
  - 어떤 OS 커널은 여러 개의 페이지 크기도 허용한다
- 운영체제는 물리 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다
  - 즉, 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇 개나 되는지 등을 알아야 한다
  - 이런 정보는 일반적으로 프레임 테이블(frame table)이라는 시스템에 하나 밖에 없는 자료구조에 있다
- 페이징은 context switching 시간을 늘린다

### 9.3.2 하드웨어 지원

- 대부분의 컴퓨터는 페이지 테이블을 메인 메모리에 저장하고
  - 페이지 테이블 기준 레지스터(page table base register, PTBR)로 하여금 페이지 테이블을 가리키도록 한다
  - context switching 시간을 줄일 수 있다

#### 9.3.2.1 Translation Look-Aside Buffer(TLB)

- 메인 메모리에 페이지 테이블을 저장하면 context switching 속도가 빨라지지만 메모리 액세스 시간이 느려질 수 있다
  - 2번 메모리에 접근해야 되므로
- 이 문제에 대한 해결에는 `TLB(Translation look-aside buffers)`라고 불리는 특수한 `소형 하드웨어 캐시`가 사용된다
  - TLB내 각 항목은 키(key)와 값(value)으로 구성된다
- 페이지 번호가 TLB에 없으면(TLB 미스), 9.3.1절에 설명된 단계에 따라 진행되며, 메모리 엑세스 및 페이지 번호와 프레임 번호를 TLB에 추가한다
- 만약 TLB가 가득차면 기존 항목 중에서 교체될 항목을 선택해야 한다.
  - 교체 정책은 LRU(Least Recently Used), 라운드 로빈, 무작위 등 다양한 정책이 사용된다
  - 어떤 TLB는 ASIDs(Adress Space IDentifier)를 저장하기도 한다
    - ASID는 그 TLB항목이 어느 프로세스에 속한 것인지를 알려주며, 그 프로세스의 정보를 보호하기 위해 사용된다
    - TLB에서 가상 주소를 변환할 때, 현재 수행 중인 프로세스의 ASID가 TLB 항목에 있는 ASID와 일치하는지 검사 후 맞지 않으면 TLB 미스로 간주한다
    - ASID 지원이 없으면 새로운 페이지 테이블이 선택될 때 마다(예를들어, 새 프로세스가 문맥 교환을 해서 실행을 재개하는 경우)
      - 다음 실행 프로세스가 잘못 변환하지 않도록 하기 위해서 TLB는 전부 비워져야(flush) 한다
- TLB에 대한 적중률의 영향을 10장에서 자세히 살펴본다

### 9.3.3 보호(Protection)

- 페이징 환경에서 메모리 보호는 각 페이지에 붙어 있는 보호 비트(protection bits)에 의해 구현된다
  - 이 비트들은 보통 페이지 테이블에 속해 있다
  - 각 비트는 이 페이지가 읽고, 쓰고 또는 읽기 전용 임을 각각 정의할 수 있다
- 페이지 테이블의 각 엔트리에는 유효/무효(valid/invalid) 비트도 있다
  - 유효(valid)로 설정되면 관련된 페이지가 프로세스의 합법적인 페이지임을 나타내며
  - 무효(invalid)로 설정되면 그 페이지는 프로세스의 논리 주소 공가에 속하지 않는 다는 것을 나타낸다
- 운영체제는 이 비트를 이용해서 그 페이지에 대한 접근을 허용하든지 또는 허용하지 않든지 할 수 있다
- 몇몇 시스템은 페이지 테이블의 크기를 나타내기 위해 `페이지 테이블 길이 레지스터(page table length register, PTLR)`라는 레지스터를 제공한다
  - 프로세스가 제시한 주소가 유효한 범위 내에 있는지를 확인하기 위해 모든 논리 주소 값이 PTLR 값과 비교된다

### 9.3.4 공유 페이지(Shared Pages)

- 페이지의 장점은 공통의 코드를 공유할 수 있다는 점이다

## 9.4 페이지 테이블의 구조(Structure of the Page Table)

## 9.5 스와핑(Swapping)

## 9.6 사례: Intel 32비트와 64비트 구조(Example: Intel 32-bit and 64-bit Architectures)

## 9.7 사례: ARM 구조(Example: ARMv8 Architecture)

## 9.8 요약(Summary)

- 메모리는 최신 컴퓨터 시스템 작동의 중심이며 각각 고유한 주소를 가진 큰 바이트 배열로 구성된다
- 각 프로세스에 주소 공간을 할당하는 한 가지 방법은 기준 및 상한 레지스터를 사용하는 것이다
  - 기준 레지스터는 가장 작은 유효한 물리 메모리 주소를 저장하며,
  - 상한은 메모리 범위의 크기를 지정한다
- 심볼릭 주소 참조를 실제 물리 주소에 바인딩하는 작업이 발생하는 경우
  - (1) 컴파일
  - (2) 적재
  - (3) 실행시간
- CPU가 생성한 주소를 논리 주소라고 하며, 메모리 관리 장치(MMU)가 메모리의 물리 주소로 변환한다
- 메모리를 할당하는 한 가지 방법은 다양한 크기의 연속 메모리 파티션을 할당하는 것이다
  - 이러한 파티션은 세 가지 가능한 적략으로 할당될 수 있다
    - (1) 최초 적합
    - (2) 최적 적합
    - (3) 최악 적합
- 최신 운영체제는 페이징을 사용하여 메모리를 관리한다
  - 이 과정에서 `물리 메모리`는 `프레임`이라는 `고정 크기 블록`으로
  - `논리 메모리`는 `페이지` 라는 `같은 크기의 블록`으로 나뉜다
- 페이징을 사용하는 경우 논리 주소는 페이지 번호와 페이지 오프셋이라는 두 부분으로 나뉜다
  - 페이지 번호는 페이지를 저장하는 물리 메모리 프레임을 유지하는 프로세스별 페이지 테이블에 대한 인덱스 역할을 한다
  - 오프셋은 참조되는 프레임의 특정 위치이다
- TLB(translation look-aside buffer)는 페이지 테이블의 하드웨어 캐시이다
  - 각 TLB 항목에는 페이지 번호와 상응하는 프레임을 저장한다
- 페이징 시스템의 주소 변환에 TLB를 사용하려면 논리 주소에서 페이지 번호를 가져와서
  - 해당 페이지의 프레임이 TLB에 있는지 확인한다
  - 만약 있다면, 프레임은 TLB로부터 얻어진다
  - TLB에 프레임이 없으면 페이지 테이블에서 찾아야 한다
- 계층적 페이징은 논리 주소를 여러 부분으로 나누고 각 단계는 서로 다른 페이지 테이블 수준을 나타낸다
  - 주소가 32비트 이상으로 확장됨에 따라 계층 레벨 수가 커질 수 있다
  - 이 문제를 해결하는 두 가지 전략은 해시 페이지 테이블과 역 페이지 테이블이다
- 스와핑을 통해 시스템은 프로세스에 속하는 페이지를 디스크로 이동하여 다중 프로그래미어 정도를 높일 수 있다
- Intel 32비트 아키텍처에는 두 가지 수준의 페이지 테이블이 있으며 4KB 또는 4MB 페이지 크기를 지원한다
  - 이 아키텍처는 또한 페이지 주소 확장을 지원하므로 32비트 프로세서가 4GB 보다 큰 물리적 주소 공간에 액세스 할 수 있다
  - x86-64 및 ARMv8 아키텍처는 계층적 페이징을 사용하는 64비트 아키텍처이다
