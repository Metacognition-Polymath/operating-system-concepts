# 5.1 기본 개념
- 다중프로그래밍의 목적은 cpu이용률을 최대화하기위해 항상 실행중인 프로세스를 가지게하는것이다. 

> 어떻게 어떤 자원들을 스케줄해줄것이냐

멀티그래밍 에서 필수적인개념
CPU 이용률을 최대한 높이기위해서 CPU스케줄링이 필요하다



### 프로세스 실행

- 전형적으로 I/O버스트, CPU 버스트 개념이 존재한다.

- 프로세스는 위 두 상태를 교대로 왔다갔다 한다. 

![](https://velog.velcdn.com/images/rodlsdyd/post/81a73fc6-04e2-4686-ac3d-addac3278b32/image.png)


CPU를쓰다가(running)
READ, WRITE를 할때 I/O를 대기한다(waiting or ready) 
일반적으로 I/O  bound가 CPU bound보다 훨씬 많다. 


## 선점형 vs 비선점형 스케줄링 

선점형 : 교체할수있다.
- 스케줄러가 CPU를 선점하고있는 프로세스를 교체할수있다.
- 다수의 프로세스에 의해 데이터가 공유된다면 race condition을 초래할 수있다.
=> 프로세스A에서 자료갱신, B에서 READ하는경우 일관성 깨진다.

비선점형 : 교체할 수 없다. (자발적으로 나오게한다)
- 프로세스가 CPU를 선점하게되면 해당 프로세스가 끝날때까지종료하거나 자발적으로 대기상태에 들어가지않는한  변환할수없다 

운영체제 커널 설계에 영향을 준다. 선점형같은경우에는 시스템콜을 처리할동안 프로세스를 위한 활동으로 바쁠수있지만, 위에서 얘기했던 일관성이 깨질수있는 문제가있고, 비선점형 커널은 커널 구조를 단순하게만들지만, 주어진시간안에 태스크의 실행이 보장되어야하는 실시간 컴퓨팅을 지원하기엔 좋은 모델이 아니다. 

- 선점형 커널은 mutex 락과같은 기법이 필요하다. 


## dispatcher

- CPU코어에 제어를 넘겨주는것 
- 모든 프로세스 context switch 발생시 호출된다.
- 컨텍스트를 하나의 프로세스에서 다른프로세스로 넘겨줘야한다
- 유저모드로 변경해준다
- 유저프로그램을 적절한 위치로 옮긴다 
- 스케줄러는 프로세스를 선택하는것이고, 실제로 switching해주는것은 dispatcher이다



### dispatcher latency
![](https://velog.velcdn.com/images/rodlsdyd/post/96f5f9ee-5326-4c95-907d-d1ef37ccaa4a/image.png)

- 최대한 짧아야한다. 


# 5.2 스케줄링의 목표
- utilization: CPU 이용률을 가능한 바쁘게 유지한다

- throughput: 프로세스의 처리량을 최대화 시킨다

- turnaround time: 프로세스를 실행하는데 소요된 시간, 최대한 줄이는것이 목표

- waiting time: **어떤 프로세스가 ready 큐에서 대기하고있는 시간을 최소화시킨다**

- response time: 응답시간을 최소화시킨다.

> CPU스케줄링에대해서 따질때
CPU이용률, 처리량, 처리시간, 대기시간, 응답시간을 평가기준으로 볼수있다.

# 5.3 스케줄링 알고리즘

## FCFS(First-Come, First-Served 스케줄링)
- 단순하고 FIFO큐로 쉽게 구현할수있다. 
- CPU를 먼저 요청한 프로세스에게 CPU를 할당시킨다. 
- 비선점형

![](https://velog.velcdn.com/images/rodlsdyd/post/d9a9a54f-6d7f-4cbb-bbcc-a7534738a9c5/image.png)
A,B,C가 거의 동시에 도착했다고 가정

처리시간 = (10+20+30) / 3 = 20

### 문제점
![](https://velog.velcdn.com/images/rodlsdyd/post/bb91d0fc-1a1b-4940-b469-62756d7e4d21/image.png)

A가 B,C보다 먼저왔기때문에 100초간 선점한다. 
처리시간 = (100 + 110 + 120) / 3 = 110 

=> convoy effect 문제가 생긴다.

편의점에서 콜라 하나만 샀는데, 앞에서 카트 여러개에 물건을 가득차서 계산하는걸 기다리는경우 


- CPU를 많이 쓰는 프로세스랑 IO를 많이쓰는 프로세스가 존재한다면?
=> CPU를 많이 쓰는 프로세스가 먼저온다면 CPU를 잠깐만 사용하면 되는 IO를많이쓰는 프로세스가 계속해서 뒤에서 대기하게된다.

- FCFS로는 좋은효율을 얻을수없다. 


## SJF(Shortest-Job-First 스케줄링)
소량 구매용 계산대를 갖추는것
![](https://velog.velcdn.com/images/rodlsdyd/post/6bbcc29a-51ca-48b5-9d6b-8bb908323e3a/image.png)
A,B,C를 실행시킨결과 -> 평균 처리시간이 짧은 작업부터 실행

처리시간 : (10+20+120) / 3 = 50 
=> 2배 이상향상

### 문제점
- 모든 작업이 동시에 도착한다면 SJF가 최적의 스케줄링 알고리즘임을 증명할수있다. 하지만 동시에 도착하는작업들이 임의의 시간에 도착한다면?

![](https://velog.velcdn.com/images/rodlsdyd/post/ecc00394-505a-4457-b64d-82b1c6bc675a/image.png)

=> A가 먼저 도착한후, 조금지나 B,C가 도착한다면?  또다시 convoy effect 발생 

- 엄격하게 적용할순없고 근사적으로 예측해서 사용할수있다. 
  -  이전의 CPU burst를 보고 (5ms 쓰고 나가더라, 4ms쓰고 나가더라 이러면 과거를 보고 CPU를 많이 안쓰는작업인지 판단한다) 지수적 평균을 측정한다. 
  
  - 새로운 프로세스가 들어올떄마다 현재 실행중인 프로세스와 비교해서 실행시킬거냐 말거냐를 정해야하기때문에 구현하는게 쉽지는않다. 

- 선점형일수도있고, 비선점형 일수도있다. 
=> 선점형이 더 유리하다 


#### SRTF
- 남은시간이 짧은것부터 실행하는 선점형 SJF 스케줄링
- 새로운 작업이 시스템에 들어오면 남아있는 작업과 새로운작업의 잔여 실행시간을 계산하고 가장 잔여 실행시간을 적게 가진 작업을 스케줄한다.
![](https://velog.velcdn.com/images/rodlsdyd/post/74c864f2-b4ff-4ccc-9cb1-f13a5bac3ea7/image.png)

A를 선점하다가 B와C가 잔여시간이 짧기때문에 작업이 B,C로 넘어가고 A가 마저 수행된다

처리시간 : (120 + 20-10 + 30-10) / 3  = 50 


#### 고려해볼점

- 여태까지 처리시간이 가장짧은 것을 기준으로 최적의 스케줄링을 선정했다.

- 응답시간을 고려해본다면?
=> A의 응답시간은 0, B는 0, C는 10, => 평균 3.33 

![](https://velog.velcdn.com/images/rodlsdyd/post/0085598e-b5c1-4613-99f3-19d0b61cdff3/image.png)

- 3개의 작업이 동시에 들어온다면, 결국 마지막에 있는 작업은 응답이올때까지 10초이상을 기다릴수도있다. 


## RR(라운드 로빈) : 시간을 정해놓고 쪼개진 시간에 프로세스 적재 (현대 운영체제에서 다 쓴다)
- 작업이 끝날때까지 기다리지않고 타임슬라이스동안 실행한후 실행큐의 다음작업으로 전환한다
- **응답시간에 매우 유효**하다

![](https://velog.velcdn.com/images/rodlsdyd/post/ba43aaa6-e027-4b3b-b288-040b5e9cf93f/image.png)

RR평균 응답시간 = (0+1+2) / 3 = 1 
SJF 평균응답시간 = (0+5+10) / 3 = 5

- 타임슬라이스 길이가 매우 중요하다
=> 타임슬라이스를 너무 짧게 지정하면? context switching 비용이 전체 성능에 영향을 준다
=> 예를들어서, 타임슬라이스를 10msec로 설정하고 context switching비용이 1msec 일경우 10%의 시간이 context switching에 사용되기때문에 낭비라고 보며, 이때 100msec로 늘려 1%소모로 줄일수 있다. 너무 길어지면 또 안된다.

- 처리시간이 유일한 측정기준인경우, RR은 최악일수있지만 각 작업을 가능한늘리는것이 목표다. 

SJF,STCF 는 반환시간을 최적화하지만 응답시간은 나쁘다.
RR은 응답시간을 최적화하지만 반환시간이 나쁘다. 흔히말하는 트레이드오프


- waiting time은 조금더 길어질수있지만 SJF를 같이 섞어쓰는경우도 있다.

#### 고려해볼점

- RR은 응답시간을 단축시키지만 처리시간은 거의 최악이다.
- 여태 다뤘던 알고리즘들은 작업의 실행시간정보를 필요로 했지만, 현실적으로 운영체제는 실행시간을 미리 알수없다.
- 정보 없이 응답시간을 최소화하고 처리시간도 최소화할수있는 스케줄러를 어떻게 설계할까?



## 멀티레벨 피드백 큐 스케줄링(MLFQ)
- 우선순위를 동적으로 부여한후 처리하는방식
- 여러개의 큐로 구성되며 각각 다른순순위가 배정된다 

- A의 우선순위가 B의 우선순위보다 크면 A가 실행된다.
- A의 우선순위와 B의우선순위가 같다면 A와 B는 라운드로빈 방식으로 실행된다. 
![](https://velog.velcdn.com/images/rodlsdyd/post/429d9aa9-8017-4809-92ab-8b5d448316da/image.png)

### 우선순위 변경방법

규칙1. 작업이 진입하면 가장 높은우선순위, 큐의 맨위에 놓여진다
규칙2. 주어진 타임슬라이스를 모두 사용하면 우선순위가 한단계 내려간다
규칙2-2. 타임슬라이스를 소진하기전에 cpu를 양도하면 같은 우선순위를 유지한다 

#### 1개의 긴 작업이 들어온경우
![](https://velog.velcdn.com/images/rodlsdyd/post/70c561f8-574d-4739-8642-aaf7e0655f52/image.png)

10msec 타임슬라이스를 사용할때마다 우선순위가 강등되고 이후 쭉 Q0에 머무른다. 
 
#### 짧은 대화형 작업이 들어온경우
![](https://velog.velcdn.com/images/rodlsdyd/post/8ebec6bc-d875-4081-ba08-1bdc46625bd9/image.png)

검정작업을 실행하다가 새로운 회색(대화형작업) 작업이 들어온경우 , Q0에 도착하기전에 종료한다. 그리고 검정작업을 재개한다. 

>  스케줄러는 짧은작업인지 긴작업인지 알수없기때문에** 일단 짧은 작업이라고 가정해서 높은우선순위를 부여한다.** 
=> 짧은작업이 아니어도, 천천히 아래큐로 이동해서 스스로 긴 작업이라는것이 증명된다.
=> MLFQ가 SJF를 근사할수있다는 얘기

#### 프로세스가 타임슬라이스를 소진하기전에 양도하는경우

대화형작업이 키보드나 마우스같은 사용자 입력을 대기하면서 자주 입출력을 수행하면 타임슬라이스를 다 쓰기전에 cpu를 양도하게된다. 이경우 동일한 우선순위를 유지하게된다.
![](https://velog.velcdn.com/images/rodlsdyd/post/91c72103-ab68-45df-a5b3-409038d0ddc4/image.png)

회색은 I/O수행전 1msec만 실행되고 검정색은 긴 작업으로 회색과 CPU를 사용하기위해 경쟁한다. 
이때 회색은 타임슬라이스를 다 사용하기전에 CPU를 양도하기때문에 높은우선순위가 유지된다. 회색이 대화형 작업이라면 대화형 작업을 빨리 실행시킨다는 목표에 근접하게된다.

#### 문제점

- 기아상태가 발생할수있다
=> 너무많은 대화형 작업이존재하면 그 작업들이 모든 CPU시간을 소모하게되고 긴 실행시간을 가진 작업을 CPU시간을 할당받지 못한다.(starvation)

- 타임슬라이스의 99%만 실행하고 CPU를양도해서 우선순위를 계속유지한상태로 CPU를 독점하는게 가능하다. (타임슬라이스가 끝나기전에 아무파일을 대상으로 I/O요청을 내려 CPU를 양도가 가능하다) 

- CPU위주의 작업이 대화형작업으로 변경된다면?



### 기아문제를 방지하기위한 우선순위 상향

- 일정기간이 지나면, 시스템의 모든작업을 최상위큐로 이동시킨다는 규칙

![](https://velog.velcdn.com/images/rodlsdyd/post/fa174fc0-f619-42e4-8c39-76067a5e50db/image.png)


=> 모든 프로세스는 굶지않게되며, 최상위 큐에 존재하는동안 RR방식으로 CPU를 공유하게된다.(기아상태의 문제 해결)

=> CPU위주의 작업이 대화형작업으로 변한다면 우선순위를 향상시킨다. (작업이 변하는 문제 해결)

#### 고려해볼점
- 일정기간을 어느정도로 잡아야하는가? 
- CPU 독점 문제 


### CPU독점을 방지하기위한 기간 측정 : 강등
CPU 총 사용시간을 측정해서 프로세스가 타임 슬라이스에 해당하는 시간을 모두 소진하면 다음 우선순위 큐로 강등된다.
![](https://velog.velcdn.com/images/rodlsdyd/post/ef72d6cd-5ad6-4e2d-a06c-95beb99b7a12/image.png)

좌측은 강등이 없는경우, CPU독점 조작에대한 내성이 없고 우측은 강등이있기때문에 독점문제를 해결할수있다. 


### 더 많은 의문들

- 몇개의 큐가 존재해야하는가?
- 타임슬라이스의 크기는 얼마로 해야하는가?
- 기아를 해결하기위해 얼마나 자주 우선순위를 상향시켜야하는가?

=> 쉽게 대답할수없고, 계속 조정해나가면서 균형점을 찾아야한다. 

=> 일반적으로 우선순위가 높은큐는 짧은 타임슬라이스가 주어지고 이 큐는 대화형 작업들로 구성된다. 이 작업들은 빠르게 교체하는것이 의미가있다. 

=> 낮은 우선순위는 CPU중심의 오래 실행되는 작업들을 포함한다. 긴 타임 슬라이스가 적합하다. 

![](https://velog.velcdn.com/images/rodlsdyd/post/48edb3c2-3c81-4ecc-a083-2e9a6acc09d4/image.png)

우선순위가 높은것들은 짧은 타임슬라이스, 긴것들은 우선순위가 낮다. 


- 작업의 특성에대한 **정보없이 작업의 실행을 관찰한후** 우선순위를 지정할수있다.

- 반환시간, 응답시간을 모두 최적화한다. 
- 짧게 실행되는 대화형 작업에대해 우수한 성능을 제공한다. 
- 오래 실행되는 CPU집중 작업에 공정하게 실행하고 조금이라도 진행되도록한다. 

윈도우 운영체제, BSD UNIX와 여기서 파생된 다양한 OS에서 기본스케줄러로 사용한다


## 멀티 프로세서 스케줄링

todo
여러 CPU에 작업을 어떻게 스케줄해야할것인가

### 멀티 프로세서 시스템에서 캐시를 사용하는것은 복잡하다
![](https://velog.velcdn.com/images/rodlsdyd/post/a1b3e8a2-ee86-4713-89c4-f7cfba408650/image.png)

CPU1에서 실행중인 프로그램이 주소 A를 읽는다고 가정하면 데이터가 CPU1캐시에 존재하지않기때문에 시스템은 메인메모리로부터 데이터를 가져오고 값 P를 얻는다. 
-> 프로그램은 주소 A의 값을 변경한다. 변경은 캐시에 존재하는값만 P1로 갱신한다. 
=> 메모리에 데이터를 쓰는것은 오래걸리므로 메인메모리에 기록은 보통 나중에 한다. 

OS가 프로그램의 실행을 중단하고 CPU2로 이동하여 프로그램 주소 A의 값을 읽으면 CPU2의 캐시에는 데이터가 존재하지않고 메인메모리에서 데이터를 가져온다. 이때 P1이 아닌 옛날값인 P를 가져온다. 
=> 캐시 일관성 문제라고한다. 

캐시일관성, 동기화, 캐시친화성을 고려해야한다


# 5.5 멀티 프로세서 시스템 스케줄러 개발방법 - (1)단일 큐 스케줄링(SQMS)

단점
- 확장성이 결여된다
=> 스케줄러가 다수의 CPU에서 제대로 동작하게 하기위해 코드에 락을걸기때문에 성능이 크게 저하된다(특히나 CPU개수가 증가할수록)

- 캐시 메모리를 효율적으로 사용할수없다
=> CPU에서 실행될때, 프로세스는 해당 CPU캐시에 많은 양의 상태 정보를 올려놓기 때문에 다음번에 프로세스가 실행될때 동일한 CPU에서 실행되는것이 유리하다. 해당 CPU캐시에 일부정보가 이미 존재하고있기 때문이다. 

프로세스가 매번 다른 CPU에서 실행되면 실행할때마다 필요한정보를 캐시에 다시 탑재해야하므로 프로세스의 성능은 더 나빠질것이다. (하드웨어의 캐시 일관성 프로토콜 덕분에 다른 CPU에서 실행되더라도 프로그램이 제대로 실행되긴한다)

![](https://velog.velcdn.com/images/rodlsdyd/post/49d2749d-3a70-4fab-bc90-48f650eeb185/image.png)

실행할 5개의 작업이 있고 4개의 프로세스가 있다고 가정해보자
![](https://velog.velcdn.com/images/rodlsdyd/post/12d9571e-e204-478c-ad01-9938d99bc82e/image.png)

각 작업은 주어진 타임슬라이스동안 실행될것이다. 
위 그림은 CPU 0,1,2,3이 하나의 공유큐에서 다음작업을 계속 선택하기때문에 캐시친화성 관점에서 잘못된선택을 하는것이라고 볼수있다.

이 문제를 해결하기위해 가능한 프로세스가 동일한 CPU에서 재실행될수있도록 시도해야한다. 

![](https://velog.velcdn.com/images/rodlsdyd/post/69e31850-52f8-406f-9259-b96d0adab917/image.png)

E를제외한 작업 A~D는 각각 자신의 프로세서에만 실행된다. 
이 방식은 구현하기 복잡하고 동기화 오버헤드때문에 확장성이 좋지않다. 


## (2) - 멀티레벨 큐 스케줄링
CPU마다 큐를 하나씩 두는 방식, 멀티 큐 멀티 프로세서 스케줄링이라고도 부른다.

- 각 큐는 라운드로빈같은 특정 스케줄링 규칙을 따를것이고 적당한 방법을 통해 작업이 스케줄링 큐에 배치된다

- 각각 독립적으로 스케줄되기때문에 동기화문제를 피할수있다.
![](https://velog.velcdn.com/images/rodlsdyd/post/0b91b1d8-2626-48f7-a0a5-266bd174757f/image.png)
2개의 CPU와 A,B,C,D 네개의 작업이 존재한다고 가정했을때 위와같이 작업을 배치하기로 결정했다면 라운드로빈 정책으로 결정된경우 스케줄은 아래와같이 생성될수있다.
![](https://velog.velcdn.com/images/rodlsdyd/post/c4f824ff-9a1c-4921-9bb3-19df6b0016ef/image.png)
이방식은 확장성이 좋다는 이점이있다. cpu개수가 증가할수록 큐의 개수도 증가하므로 락,캐시경합은 더이상 문제되지않는다. 

또한, 작업이 같은 CPU에서 실행되기때문에 캐시에 저장된 내용을 재사용하는 이점을 얻게된다. 

#### 문제점
![](https://velog.velcdn.com/images/rodlsdyd/post/61be5fe5-76ec-49c3-b187-124127cbb89e/image.png)
위에 했었던 가정에서 c가 종료되고, 각 큐에서 라운드로빈 정책을 실행한경우 스케줄은 아래와 같다 

![](https://velog.velcdn.com/images/rodlsdyd/post/8e2a155d-c251-4d2a-a94a-4e9e057574ae/image.png)

  만약 A,C 모두 종료된다면?
![](https://velog.velcdn.com/images/rodlsdyd/post/b1ef7012-8d99-49de-8861-bd0bc0f9b416/image.png)

CPU0은 유휴상태가 된다. 

### 해결법

작업을 이리저리로 이동시킨다.(책에선 로드밸런싱 방법이라고 설명한다)
os가 b또는 D중하나를 CPU0으로 이동시킨다. 

A가 남아있던경우에는?
![](https://velog.velcdn.com/images/rodlsdyd/post/2f868c3b-cfc6-4147-bc7b-945498e49d16/image.png)

B가 CPU0으로 이주해서 A랑 경쟁하고 D는 CPU1에서 몇개의 타임슬라이스동안 혼자 실행되어 균형을 유지한다. 

- 작업 훔치기라는 기본적인 접근법이있는데, 이는 작업의 개수가 낮은 큐가 가끔씩 다른 큐에 훨씬 많은수의 작업이있는지 검사하고 균형을 맞추기위해 이주하는방법 

=> 큐를 자주 검사하게되면 오버헤드로 확장성 문제가생기고, 자주 검사하지않으면 불균형문제가 생긴다. 


단일 큐 방식은 구현이 용이하고, 작업의 균형을 맞추기 용이하지만 확장성과 캐시친화성이 좋지못하다

멀티 큐 방식은 확장성이 좋고 캐시친화성이 좋지만 작업의불균형 문제가있고 구현이 복잡하다. 

CPU스케줄러는 사소한 코드수정으로 시스템의 동작이 엄청 바뀌기떄문에 모든 경우를 커버하는 범용 스케줄러를 구현하는것은 매우 어렵다. 


멀티큐를 사용하는경우, 단일큐를 사용하는경우 두방식 모두 실제로 시스템에서 성공적으로 사용할수있다. 

# 5.6 실시간 CPU 스케줄링

소프트 리얼타임
- 아무런 보장을 하지않는것

하드리얼타임
- 반드시 데드라인안에 작업이 실행되는것

### 지연시간 최소화
실시간시스템은 가능한 빨리 그에 응답하고 맞는 동작을 수행해야한다.
이벤트가 지연되는 두가지 유형의 지연시간도 존재한다.

![](https://velog.velcdn.com/images/rodlsdyd/post/541eb959-f546-4cb4-9e7c-247c466f1d94/image.png)

인터럽트 지연시간
- CPU에 인터럽트가 발생후 처리가 시작되기까지의 시간
- 인터럽트 발생시 수행중인 프로세스의 상태를 저장해놓는것이 지연시간이라고 볼수있다.

![](https://velog.velcdn.com/images/rodlsdyd/post/81b0e437-ad50-4f44-b5dc-02b3999e1d6c/image.png)

디스패치 지연시간
- 스케줄링 dispatcher가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는데까지 걸리는시간, 실시간 태스트인경우 이 지연시간을 최소화해야한다. 

### 우선순위 기반 스케줄링
실시간 OS에서 가장 중요한 건 실시간 프로세스에 CPU가 필요할 때 바로 응답을 해주는 것이다.
따라서 실시간 운영체제의 스케줄러는 선점기법을 이용한 우선순위 기반의 알고리즘을 지원해야만 한다.

스케줄러가 선점기법을 제공한다면, 현재 CPU를 이용하고 있는 프로세스가 더 높은 우선순위를 갖는 프로세스에 선점될 수 있다.

### Rate-Monotonic 스케줄링

- 낮은 우선순위의 프로세스가 실행중이고 높은 우선순위의 프로세스가 실행준비가되면 높은 우선순위의 프로세스가 선점하는것 

- 프로세스의 개수에 따라 CPU자원을 최대한 활용할수는 없음
1개인경우에는 100%, 프로세스가 증가하면 100%를 달성할수없음

### EDF 스케줄링

- 마감 기한에 따라 동적으로 우선순위 부여한다
- 마감 기한이 빠른 순으로 우선순위 부여한다
- 프로세스가 실행 가능할 때 반드시 시스템에 자기 마감 기한 소요를 알려서 우선순위 갱신해야 한다.


## 5.7 운영체제 사례들

리눅스 
- 2.6.23커널부터 CFS(완전 공평스케줄러)가 디폴트 스케줄링 알고리즘이 되었다. 이외에도 RR, 우선순위기반 스케줄러를 포함해 다양한 스케줄링 정책을 사용한다. 

- CFS 스케줄링 알고리즘을 사용하는 디폴트 스케줄링클래스, 실시간 스케줄링 클래스의 두 스케줄링 클래스를 구현한다. 

- CFS는 직접 우선순위를 할당하지않고 각 태스크별로 가상실행시간을 유지한다. ( 이값을 레드블랙트리 형태로 관리한다)

- 스레드를 이주시켜 로드밸런싱 하는 형식, 이때 캐시 메모리를 효율적으로 사용하기위해 스케줄링 도메인 개념을 도입한다 (그림5.27)

윈도우

- 우선순위 기반의 선점스케줄링 알고리즘을 사용한다.

- 포그라운드, 백그라운드 프로세스를 구분해서 프로세스가 포그라운드가되면 타임슬라이스를 3배정도 증가시킨다. 

- 리소스 사용량에 따라 프로세스의 우선순위를 동적으로 조정한다. 
=> 프로세스가 많은CPU시간을 사용하면 다른 프로세스가 CPU시간이 부족하지않도록 우선순위 수준을 낮출수있다.
