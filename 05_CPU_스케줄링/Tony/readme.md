# 5. CPU 스케줄링(Scheduling)

CPU 스케줄링은 다중 프로그램 운영체제의 기본이다

운영체제는 CPU를 프로세스 간에 교환함으로써, 컴퓨터를 보다 생산적으로 만든다

스케줄링 개념 소개, 스케줄링 알고리즘 제시

운영체제는 프로세스가 아니라 커널 수준 스레드를 스케줄 한다

일반적인 스케줄링 개념 : 프로세스 스케줄링

스레드에 국한된 개념을 가리키는 경우 : 스레드 스케줄링

1코어 : CPU의 기본 계산 단위

- 프로세스가 CPU 코어에서 실행되는 방식에 관해 설명

프로세스를 스케줄링하여 "CPU에서 실행"

- 프로세스가 CPU 코어에서 실행되고 있음을 의미

#### 이 장의 목표

- 다양한 CPU 스케줄링 알고리즘을 설명한다
- 스케줄링 기준에 따라 CPU 스케줄링 알고리즘을 평가한다
- 다중 처리기(Multi-processor) 및 다중 코어 스케줄링과 관련된 쟁점을 설명한다
- 다양한 실시간 스케줄링 알고리즘을 설명한다
- Windows, Linux 및 Solaris 운영체제에서 사용되는 스케줄링 알고리즘을 설명한다
- CPU 스케줄링 알고리즘을 평가하기 위해 모델링 및 시뮬레이션을 적용한다
- 여러 가지 다른 CPU 스케줄링 알고리즘을 구현하는 프로그램을 설계한다

## 5.1 기본 개념(Basic Concepts)

- 다중 프로그래밍의 목적은 CPU 이용률을 최대화
- 어떤 프로세스가 대기해야 할 경우, 운영체제는 CPU를 그 프로세스로 부터 회수해 다른 프로세스가 CPU 사용을 양도받을 수 있다
- 이러한 스케줄링은 운영체제의 기본 기능이다
- CPU는 컴퓨터의 중요한 자원 중 하나이고 CPU 스케줄링은 운영체제 설계의 핵심이 된다

### 5.1.1 CPU - I/O Burst Cycle

- 프로세스 실행은 CPU 실행과 I/O 대기의 사이클로 구성된다
- CPU burst : 프로세스가 CPU를 사용하는 시간
- I/O burst : 프로세스가 I/O를 수행하는 시간
- 짧은 CPU 버스트가 많고, 긴 CPU 버스트는 적다

### 5.1.2 CPU 스케줄러

- CPU 스케줄링 결정은 다음의 네 가지 상황에서 발생할 수 있다
  - (1) 한 프로세스가 `실행 상태 -> 대기 상태`로 전환 될때
    - e.g. wait() 시스템 콜
  - (2) 프로세스가 `실행 상태 -> 준비 완료` 상태로 전환될 때
    - e.g. 인터럽트가 발생할 때
  - (3) 프로세스가 `대기 상태 -> 준비 완료` 상태로 전환될 때
    - e.g. I/O 종료 시점
  - (4) 프로세스가 종료할 때
- 1, 4 : 선택의 여지 없이 반드시 선택되어야 함
- 2, 3 : 선택의 여지가 있음

#### 선점형(preemptive), 비선점형(non-preemptive)

- `선점형` 스케줄링 : 스케줄러가 프로세스를 `강제로` 중단시키는 스케줄링
  - 프로세스가 CPU를 점유하고 있을 때, 스케줄러가 강제로 다른 프로세스를 CPU에 할당
  - 공유 커널 데이터 구조에 액세스 할 때 경쟁 조건을 방지하기 위해 mutex lock과 같은 기법이 필요
  - 대부분 `최신 운영체제는` 완전한 `선점형` 스케줄링을 지원
- 비선점형 스케줄링 : 스케줄러가 프로세스를 강제로 중단시키지 않는 스케줄링
  - 한번 CPU가 할당 되면 CPU를 방출할 때 까지 점유
  - 실시간 컴퓨팅을 지원하기에는 좋은 모델이 아니다

### 5.1.4 디스패처(Dispatcher)

- 디스패처는 CPU 코어의 제어를 CPU 스케줄러가 선택한 프로세스에 주는 모델

  - dispatcher : 스케줄러가 선택한 프로세스에 CPU를 할당하는 모듈

- dispatcher가 하는 일

  - 한 프로세스에서 다른 프로세스로 context switch
  - 사용자 모드로 전환
  - 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동(jump)

- 디스패치 지연(dispatcher latency) : 디스패처가 프로세스를 CPU에 할당하기 위해 걸리는 시간
- context switching이 얼마나 자주 발생하는가?

  - (linux) vmstat 명령어를 사용하여 확인 가능
    - e.g. vmstat 1 3 : 1초 지연단위로 3줄의 출력을 제공한다

- 자발적 문맥 교환 vs 비자발적 문맥 교환
  - 자발적 문맥 교환(voluntary context switch) : 프로세스가 자신을 중단시키는 것
    - e.g. I/O를 기다리며 대기 상태로 전환
  - 비자발적 문맥 교환(involuntary context switch) : 프로세스가 자신을 중단시키지 않고 스케줄러에 의해 중단되는 것
    - e.g.
      - 시간 할당량(tiem slice)이 만료되어 대기 상태로 전환
      - 우선순위가 높은 프로세스가 낮은 우선순위 프로세스를 중단시키는 것

## 5.2 스케줄링 기준(Scheduling Criteria)

- CPU 알고리즘을 비교하기 위한 기준

  - CPU 이용률(CPU utilization)
  - 처리량(throughput)
  - 총처리 시간(total turnaround time)
    - 준비 큐에서 대기한 시간 + CPU에서 실행하는 시간 + I/O 시간
  - 응답 시간(response time)
    - 대화식 시스템(interactive system)에서는 총처리시간 보다 응답시간이 더 중요한 기준이 될 수도 있다
    - 응답이 시작되는 데 까지 걸리는 시간(그 응답을 출력하는 데 걸리는 시간은 아님)

- 연구자들은 대화식 시스템(PC 데스크톱 혹은 랩톱 시스템)의 경우 평균 응답 시간을 최소화하기 보다는 응답 시간의 편차(variance)를 최소화하는 것이 중요하다고 제시하고 있다
- 이후 논의에서 CPU 버스트와 I/O 버스트들을 포함하는 많은 프로세스를 고려해야 하지만
  - 설명을 간단히 하기 위해 CPU 버스트만을 고려하기로 한다
  - 여기서 비교하려는 기준은 `평균 대기 시간(average waiting time)`이다
  - 더 자세한 평가 기법은 5.8절에서 논의한다

## 5.3 스케줄링 알고리즘(Scheduling Algorithms)

- CPU 스케줄링은 ready queue에 있는 어느 프로세스에 CPU 코어를 할당하는 것인지를 결정하는 문제를 다룬다
- 내 생각) 문득 다양한 CPU 알고리즘이 있듯, 다양한 AI 알고리즘이 존재할 것 같다는 생각이 든다 -> github copilot의 추천 문구가 그런 것 같다

- 대부분 최신 CPU 아키텍처는 여러 개의 처리 코어가 있지만 이러한 스케줄링 알고리즘은 처리 코어가 하나뿐이라고 가정하고 설명한다
  - 5.5절에서 다중 처리기 시스템에서의 cpu 스케줄링에 대해 설명한다

### 5.3.1 FCFS(First-Come, First-Served)

- 선입 선처리 스케줄링
- 가장 간단한 스케줄링 알고리즘
- 프로세스가 준비 큐에 도착한 순서대로 CPU를 할당
  - FIFO 큐로 쉽게 관리할 수 있다
- 비선점형(non-preemptive) 스케줄링
  - 그 프로세스가 종료하든지 또는 I/O 처리를 요구하든지하여 CPU를 방출할 때 까지 CPU를 점유한다
- 대화형 시스템에서 문제가 되는데, 그 이유는
  - 대화형 시스템에서는 각 프로세스가 규칙적인 간격으로 cpu 몫을 얻는 것이 매우 중요하기 때문이다
  - 한 프로세스가 지나치게 오랫동안 CPU를 점유하게 허용하는 것은 손해가 클 것이다

### 5.3.2 SJF(Shortest-Job-First)

- 최단 작업 우선 스케줄링
- 각 프로세스에서 다음 CPU 버스트 길이를 연관시킨다
- CPU가 이용가능해지면 `가장 작은 다음 CPU버스트`를 가진 프로세스에 할당한다
  - == 최단 다음 cpu 버스트 (shortest-next-CPU-burst) 알고리즘
- 최소 평균 대기 시간을 가진다
  - 하지만 다음 CPU 버스트의 길이를 알 방법이 없다
  - 그 값을 예측 -> 일반적으로 측정된 이전의 CPU 버스트들의 길이를 지수(exponential) 평균한 것으로 예측
    - 과거 또는 최근에 가중치를 주고 평균을 구하는 것
- 선점형(preemptive) 또는 비선점형(non-preemptive) 일 수 있다
  - 선점형 SJF == SRTF(Shortest-Remaining-Time-First)
    - 최소 잔여 시간 우선 스케줄링

### 5.3.3 라운드 로빈 스케줄링(Round-Robin Scheduling)

- FCFS와 유사하지만 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점(preemptive)이 추가된다
- 시간 할당량(time quantum) 또는 타임 슬라이스(time slice)라고 불리는 일정한 시간 간격을 정의한다
  - 일반적으로 10에서 100밀리초(ms)
- 준비 큐는 원형 큐(circular queue)로 동작한다
- 한 번에 한 프로세스에서 한 번의 시간 할당량 동안 CPU를 할당한다
- 라운드 로빈 스케줄링 구현
  - 준비 큐가 FIFO 큐로 동작하게 만든다
  - 새로운 프로세스들은 준비 큐의 꼬리에 추가된다
  - CPU 스케줄러는 준비큐에서 첫 번째 프로세스를 선택해 한 번의 시간 할당량 이후에 인터럽트를 걸도록 타이머를 설정한 후, 프로세스를 디스패치(전환)한다
- 라운드 로빈 프로세스 전환 경우
  - (1) 프로세스의 CPU 버스트가 한번의 시간 할당량 보다 작은 경우
    - 프로세스 자신이 CPU를 자발적으로 방출 -> 다음 준비 큐의 프로세스에게 CPU를 할당
  - (2) 현재 실행 중인 CPU 버스트가 시간 할당량 보다 긴 경우
    - 타이머가 끝나고 운영체제에 인터럽트를 발생
    - 실행중이던 프로세스는 준비 큐의 꼬리로 이동
    - context switching이 발생(다음 프로세스 전환)
- RR알고리즘 성능은 시간 할당량의 크기에 매우 많은 영향을 받는다
  - 극단적인 경우, 시간할당량이 매우 크면, RR정책은 FCFS와 같아진다
  - 반대로 시간 할당량이 매우 적다면 RR정책은 매우 많은 문맥 교환을 발생시키며, 이는 성능을 저하시킨다

### 5.3.4 우선순위 스케줄링(Priority Scheduling)

- SJF 알고리즘도 우선순위 스케줄링 알고리즘의 특별한 경우이다
- 우선순위가 각 프로세스들에 연관되어 있으며, CPU는 가장 높은 우선순위를 가진 프로세스에 할당된다
- 우선순위 스케줄링은 선점형(preemptive) 또는 비선점형(non-preemptive) 일 수 있다

#### 우선순위 스케줄링의 문제점

- 무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation)
  - 우선순위가 낮은 프로세스들이 무한히 대기하는 경우
- 해결방안
  - 노화(aging)
  - 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시킨다

### 5.3.5 다단계 큐 스케줄링(Multilevel Queue Scheduling)

- 우선순위와 라운드 로빈 스케줄링을 사용할 때 모든 프로세스가 단일 큐에 배치되고 스케줄러는 우선순위가 높은 프로세스를선택하여 실행시킬 수 있다

  - 우선순위 마다 별도의 큐 유지

- 다단계 큐(Multilevel Queue) 예시

  - 포그라운드(대화형) 프로세스 : 우선순위 높음
  - 백그라운드(배치) 프로세스 : 우선순위 낮음

- 각 큐는 다음과 같은 우선순위를 갖는다

  - 실시간 프로세스
  - 시스템 프로세스
  - 대화형 프로세스
  - 배치 프로세스

- 브라우저 예시(책에는 없지만 내가 추가한 내용)
  - https://baeharam.netlify.app/posts/javascript/JS-Task%EC%99%80-Microtask%EC%9D%98-%EB%8F%99%EC%9E%91%EB%B0%A9%EC%8B%9D
  - 태스크 큐 vs 마이크로 태스크 큐
    - (콜백함수를) 태스크 큐에 넣는 함수들
      - setTimeout, setInterval, setImmediate, requestAnimationFrame, I/O, UI 렌더링
    - (콜백함수를) 마이크로 태스크 큐에 넣는 함수들
      - Promise, process.nextTick, Object.observe, MutationObserver
  - 마이크로 태스크 큐가 먼저 실행되고, 태스크 큐가 실행된다

### 5.3.6 다단계 피드백 큐 스케줄링(Multilevel Feedback Queue Scheduling)

- 5.3.5의 다단계 큐에선 단계별 큐 사이에 이동되지 않았었다
  - 오버헤드가 장점이 있으나 융통성이 적다
- 다단계 피드백 큐에선 프로세스가 큐들 사이를 이동하는 것을 허용한다
  - aging -> starvation 문제 해결
- Multilevel Feedback Queue(다단계 큐) 스케줄러는 다음의 매개변수에 의해 정의 된다
  - 큐의 개수
  - 각 큐를 위한 스케줄링 알고리즘
  - 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
  - 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
  - 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법
- 가장 복잡한 알고리즘

## 5.4 스레드 스케줄링(Thread Scheduling)

- 사용자 수준과 커널 수준 스레드의 스케줄링에 관한 쟁점을 탐구하고
- Pthread의 스케줄링 사례를 제공한다

### 5.4.1 경쟁 범위(Contention Scope)

- 다대다 모델 : LWP상에서 스케줄
  - 프로세스에 속한 스레드들 사이에서 CPU를 경쟁 -> 프로세스-경쟁-범위(process-contention scope, PCS)로 알려져 있다
- CPU상에 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해서 커널은 시스템-경쟁-범위(system-contention scope, SCS)를 사용한다

- Windows와 Linux 같은 (사용자 스레드 : 커널 스레드)일대일 모델을 사용하는 시스템은 오직 SCS만을 사용하여 스케줄한다
- PCS(프로세스-경쟁-범위)는 전형적으로 우선순위에 따라 행해진다
  - 스케줄러는 가장 높은 우선순위를 가진 프로세스를 선택한다
- PCS는 통상 더 높은 우선순위의 스레드를 위해 현재 실행 중인 스레드를 선점한다는 것을 주의해야 한다
  - 같은 우선순위의 스레드들 사이에는 타임 슬라이스(정해진 시간동안 실행되고 다른 스레드에게 CPU를 넘겨주는 것)에 대한 보장은 없다

### 5.4.2 Pthread 스케줄링

- POSIX Pthread 프로그램의 예
- 이제는 `스레드를 생성`하면서 `PCS 또는 SCS를 지정할 수 있는 POSIX Pthreads API를 강조`한다
- Pthreads는 다음과 같은 범위 값을 구분
  - PTHREAD_SCOPE_PROCESS : PCS 스케줄링을 사용하여 스레드를 스케줄
  - PTHREAD_SCOPE_SYSTEM : SCS 스케줄링을 사용하여 스레드를 스케줄
- 다대다 모델을 구현하는 시스템에서는 PTHREAD_SCOPE_SYSTEM 정책
  - 사용자 수준 스레드를 가용한 LWP로 스케줄
- Linux와 macOS 시스템은 PTHREAD_SCOPE_SYSTEM만을 허용

## 5.5 다중 처리기 스케줄링

- 지금까지 단일 코어를 가진 시스템에서 CPU를 스케줄 하는 문제에 주안점을 두었다
- 만일 여러 개의 CPU가 사용 가능하다면, 여러 스레드가 병렬로 실행될 수 있으므로 부하 공유(load sharing)가 가능해진다
- 그러나 스케줄링 문제는 그에 상응하여 더욱 복잡해진다
- 단일 코어 스케줄링에서도 여기에서도 최상의 해결책은 없다

- 다중 처리기 : 여러 개의 물리적 프로세스를 제공하는 시스템
- 다중 처리기
  - 다중 코어 CPU
  - 다중 스레드 코어
  - NUMA 시스템
  - 이기종 다중 처리

### 5.5.1 다중 처리기 스케줄링에 대한 접근 방법(Approaches to Multiprocessor Scheduling)

#### 마스터 서버(master server)

- 한 가지 접근 방법은 마스터 서버(master server)라는 하나의 처리기가 모든 스케줄링 결정과 I/O 처리 그리고 다른 시스템의 활동을 취급하게 하는 것이다
  - 다른 처리기들은 다만 사용자 코드만을 수행한다
- 이러한 비대칭 다중 처리(asymmetric multiprocessing)은 오직 하나의 코어만 시스템 자료구조에 접근하여 자료 공유의 필요성을 배제하기 때문에 간단하다
- 단점
  - 병목 현상(bottleneck)이 발생할 수 있다

#### 대칭 다중 처리(asymmetric multiprocessing, SMP)

- 다중 처리기를 지원하는 표준 접근 방식
- 각 프로세서는 스스로 스케줄링 할 수 있다
- 각 프로세서의 스케줄러가 ready queue를 검사하고 실행할 스레드를 선택하여 스케줄링이 진행된다
- 이는 스케줄 대상이 되는 `스레드를 관리`하기 위한 두 가지 가능한 `전략`을 제공한다(그림 5.11)

  - 전략 1) 모든 스레드가 공통 준비 큐에 있을 수 있다
    - common ready queue
    - 락킹 기법의 하나를 사용할 수 있다
      - 병목이 될 수 있다
  - 전략 2) 각 프로세서는 자신만의 스레드 큐를 가질 수 있다
    - per-processor ready queue
    - SMP(대칭 다중 처리) 시스템에서는 이 방법이 일반적이다
    - 큐 마다 부하의 양이 다를 수 있다
      - 균형 알고리즘을 사용하여 프로세서 간에 부하를 균등하게 만들 수 있다

- Windows, Linux, macOS, Android, iOS 등 모든 최신 운영체제는 SMP를 지원한다
- CPU 스케줄링 알고리즘을 설계할 때 SMP 시스템과 관련된 문제에 관해 설명한다

### 5.5.2 다중 코어 프로세서(Multi-Core Processors)

- SMP 시스템은 다수의 물리 처리기를 제공 -> 다수의 프로세스가 병렬로 실행되게 한다
- 현대 컴퓨터는 여러 개의 처리 코어를 장착하여 다중 코어 프로세서가 된다
- 다중 코어 프로세서를 사용하는 SMP 시스템은 각 CPU가 자신의 물리 칩을 가지는 시스템과 비교해 속도가 빠르고 적은 전력을 소모한다
- 다중 코어 프로세서는 스케줄링 문제를 복잡하게 한다
- 메모리 스톨(memory stall(마굿간, 매점)): 프로세서가 메모리에 접근할 때 데이터가 가용해지기를 기다리면서 많은 시간을 허비
  - 최신 프로세서가 메모리보다 훨씬 빠른 속도로 작동하기 때문에 주로 발생
  - 캐시 미스로 인해 메모리 스톨이 발생할 수도 있다
- 메모리 스톨 해결하기 위해
  - 하드웨어 설계 -> 다중 스레드 처리코어를 구현
    - 하나의 코어에 2개 이상의 하드웨어 스레드가 할당된다
    - 메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면 코어가 다른 스레드로 전환할 수 잇다
- 인텔 프로세서는 단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것을 설명하기 위해 하이퍼-스레딩(동시 다중 스레딩(simultaneous multithreading, SMT))이라는 용어를 사용한다

  - 하이퍼-스레딩은 하나의 물리적 코어에 여러 개의 논리적 코어를 할당하는 것이다
  - i7과 같은 프로세서는 코어당 2개의 스레드를 지원
  - Oracle Sparc M7 : 코어당 8개의 스레드와 프로세서당 8개의 코어를 지원
    - 64개의 논리적 CPU를 제공

- 처리기(Processor)를 다중 스레드화 하는 일반적인 방식
  - 거친(coarse-grained) 다중 스레딩
  - 세밀한(fine-grained) 다중 스레딩
- 거친 다중 스레딩

  - 스레드가 메모리 스톨과 같은 긴 지연시간을 가진 이벤트가 발생할 때까지 한 코어에서 수행
  - 긴 지연시간을 가진 이벤트에 의한 지연 -> 코어는 다른 스레드를 실행
    - 다른 스레드가 수행되기 전 명령어 파이프라인이 완전히 정리되어야 하므로 스레드 간 교환 비용이 많이 든다

- 세밀한 다중 스레딩

- 이중 스레드 처리 코어의 2단계 스케줄링

### 5.5.3 부하 균등화(Load Balancing)

- 대칭 다중 처리(asymmetric multiprocessing, SMP) 시스템에서 처리기가 하나 이상이라는 것을 최대한 활용하려면, 부하를 모든 처리기에 균등하게 배분하는 것이 매우 중요하다
- `부하 균등화`는 각 처리기가 실행할 스레드를 위한 `자기 자신만의 준비 큐를 가지고 있는 시스템에서만 필요`한 기능이다
- 공통의 실행 큐만 있는 시스템에서는 한 처리기가 쉬게 되면 곧 바로 공통 큐에서 새로운 프로세스를 선택하여 실행하기 때문에 부하균등화는 필요하지 않다

- 부하 균등화를 위해서는 push 이주(migration)와 pull 이주 방식의 두 가지 일반적인 접근법이 있다
  - push 이주
    - 태스크가 주기적으로 각 처리기의 부하를 검사하고 만일 불균형 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 스레드를 이동(push) 시킴으로써 부하를 분배한다
  - pull 이주
    - 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 `프로세스를 pull`할 때 일어난다
  - push와 pull은 상호 배타적일 필요 없이 부하 균등화 시스템에서 종종 병렬적으로 구현된다
    - Linux CFS 스케줄러와 FreeBSD 시스템에서 ULE 스케줄러는 두 방식을 모두 구현한다
- 균등 부하의 관점
  - 관점 1. 모든 큐에 대략 같은 수의 스레드가 있어야 한다
  - 관점 2. 모든 큐에 스레드 우선순위를 균등하게 분배해야 한다

### 5.5.4 처리기 선호도(Processor Affinity(밀접한 관계))

- 스레드가 특정 처리기에서 실행 중일 때 캐시 메모리에 어떤 일이 벌어지는가에 대해 고려해보자
  - 스레드 -> 캐시
  - 스레드 이주 -> 캐시 메모리의 내용은 무효화 되어야 하며, 두 번째 프로세서의 캐시는 다시 채워져야 한다
  - 캐시 무효화 및 다시 채우는 비용이 많이 들기 때문에 SMP(대칭 다중 처리)를 지원하는 대부분의 운영체제는 스레드를 한 프로세스에서 다른 프로세서로 이주시키지 않고 대신 같은 프로세서에서 계속 실행시키면서 warn cache를 이용하려고 한다
    - 이를 프로세서 선호도라고 한다
- NUMA(Non-Uniform Memory Access)
  - 각각 고유한 CPU와 로컬 메모리를 가진 두 개의 물리적 프로세서 칩이 있는 것
  - 그림 5.16

### 5.5.5 이기종 다중 처리(Heterogeneous Multiprocessing)

- 지금까지의 예 => 모든 프로세서는 기능면에서 동일하므로 어느 스레드건 모든 처리 코어에서 실행될 수 있다
- 모바일 시스템에는 현재 다중 코어 아키텍처가 채개되어 있지만 일부 시스템은 동일한 명령어 집합을 실행하지만 전력 소비를 유휴 수준으로 조정하는 기능을 포함하여 클록 속도 및 전력 관리 측면에서 `차이가 나는 코어를 사용`하도록 설계되었다
  - 이기종 다중 처리(heterogeneous multiprocessing) 시스템
- 이기종 다중 처리 ARM 프로세서 아키텍처 : big.LITTLE
  - 고성능 big 코어 + 에너지 효율적인 LITTLE 코어
- 고성능을 요구하지 않지만 백그라운드 작업과 같은 더 긴 시간 동안 실행해야 하는 작업 : little 코어에 할당
- 짧은 기간 동안 실행될 수 있는 대화형 응용 프로그램 : big 코어에 할당
- 절전 모드 : big 코어 비활성화
- Windows 10 : 스레드가 전원관리 요구를 가장 잘 지원하는 스케줄링 정책을 선택할 수 있게 하여 HMP 스케줄링을 지원한다

## 5.6 실시간 CPU 스케줄링(Real-Time CPU Scheduling)

- 실시간 운영체제에서 CPU를 스케줄링 할 때 연성(soft) 실시간 시스템과 경성(hard) 실시간 시스템으로 구분한다
  - 연성(Soft) 실시간 시스템 : 시스템이 일정 시간 내에 응답을 제공해야 하지만, 시간 내에 응답을 제공하지 못하더라도 시스템이 크게 문제가 되지 않는다
  - 경성(Hard) 실시간 시스템 : 시스템이 일정 시간 내에 응답을 제공해야 하며, 시간 내에 응답을 제공하지 못하면 시스템이 크게 문제가 된다

### 5.6.1 지연시간 최소화(Minimizing Latency)

- 인터럽트 지연시간
- 디스패치 지연시간

#### 인터럽트 지연시간

- CPU가 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기 까지의 시작 시간

#### 디스패치 지연시간

- 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 걸리는 시간

### 5.6.2 우선순위 기반 스케줄링(Priority-Based Scheduling)

### 5.6.3 Rate-Monotonic 스케줄링(Rate-Monotonic Scheduling)

- 선점(preemtive) 가능한 정적 우선순위 정책을 이용하여 주기 태스크들을 스케줄한다
- 낮은 우선순위의 프로세스가 실행 중이고 높은 우선순위의 프로세스가 실행 준비가 되면, 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점한다

### 5.6.4 Earliest-Deadline-First 스케줄링(Earliest-Deadline-First Scheduling, EDF)

- 마감 시간에 따라서 우선순위를 동적으로 부여한다

### 5.6.5 일정 비율의 몫 스케줄링(Proportionate Share Scheduling)

- 일정 비율의 몫(proportionate share) 스케줄러는 모든 응용프로그램들에 T개의 시간 몫을 할당하여 동작한다
- e.g.
  - T = 100
  - A 프로세스 : 20
  - B 프로세스 : 30
  - C 프로세스 : 50
  - A 프로세스는 20/100 = 20%의 시간을 할당받는다
  - B 프로세스는 30/100 = 30%의 시간을 할당받는다
  - C 프로세스는 50/100 = 50%의 시간을 할당받는다

### 5.6.6 POSIX 실시간 스케줄링(POSIX Real-Time Scheduling)

- SCHED_FIFO : FIFO큐를 사용하여 먼저 온 것을 먼저 서비스
- SCHED_RR : 라운드 로빈 정책, 스레드에 시간 할당량을 제공하는 SCHED_FIFO

## 5.7 운영체제 사례들(Operating System Examples)

- Windows, Solaris => 커널 스레드 스케줄링
- Linux => 태스크 스케줄링

### 5.7.1 사례: Linux 스케줄링

- CFS(Completely Fair Scheduler) : 완전 공평 스케줄러
  - 각 클래스별로 특정 우선순위를 부여받는 스케줄링 클래스에 기반을 두고 동작한다

### 5.7.2 사례: Windows 스케줄링

- 우선순위에 기반을 둔 선점(preemptive) 스케줄링

### 5.7.3 사례 : Solaris 스케줄링

- 우선순위에 따라 6개의 스케줄링 클래스를 정의
  - 시분할(time-sharing, TS)
  - 대화형(interactive, IA)
  - 실시간(real-time, RT)
  - 시스템(system, SYS)
  - 공평 공유(fair-share, FS)
  - 고정 우선순위(fixed priority, FP)

## 5.8 알고리즘의 평가(Algorithm Evaluation)

- 많은 스케줄링 알고리즘이 있다
- 알고리즘을 선택하는 것은 매우 어려운 일이다
- 알고리즘을 선택하는 데 사용할 기준을 정의
  - CPU 이용률, 응답 시간 또는 처리량 등
- 알고리즘을 선택하기 위해, 이들의 상대적인 중요성을 반드시 정의해야 한다
- 예를 들면 아래와 같은 다수의 대책을 포함할 수 있다
  - 최대 응답 시간이 300ms라는 제약 조건에서 CPU 이용률을 최대화
  - 총 처리 시간이 전체 실행 시간에 평균적으로 선형 비례가 되도록 처리량을 극대화

### 5.8.1 결정론적 모델링(Deterministic Modeling)

- 분석적 평가 : 주어진 작업 부하에 대한 알고리즘의 성능을 평가하는 공식이나 값을 생성하기 위해 주어진 알고리즘과 시스템 작업 부하를 이용
- 결정론적 모델링
  - 분석적 평가의 한 종류
  - 사전에 정의된 특정한 작업 부하를 받아들여 그 작업 부하에 대한 각 알고리즘의 성능을 정의한다
- 평균 대기 시간 기준
  - SJF가 제일 빠름
  - RR : SJF의 중간 정도
  - FCFS : 가장 느림

### 5.8.2 큐잉 모델(Queuing Model)

- CPU와 I/O 버스트의 분포 측정

### 5.8.3 모의 실험(Simulation)

- 스케줄링 알고리즘을 더욱 정확하게 평가하기 위해서 시뮬레이션을 사용할 수 있다

### 5.8.4 구현(Implementation)

- 시뮬레이션도 정확성에 한계가 있다
- 완벽히 정확하게 평가하는 유일한 방법은 실제 코드로 작성해 운영체제에 넣고 실행해 보는 것이다
- 이 방식은 비용이 많이 든다

## 5.9 요약

- CPU 스케줄링은 준비 큐에서 대기 프로세스를 선택하고 CPU를 할당하는 작업이다
  - 디스패처에 의해 선택된 프로세스에 CPU가 할당된다
- 스케줄링 알고리즘은 선점적(CPU를 프로세스로 부터 뺏을 수 있는 경우) 또는 비선점적(프로세스가 자발적으로 CPU 제어를 포기해야 하는 경우) 일 수 있다
  - 거의 모든 최신 운영체제가 선점적이다
- 스케줄링 알고리즘은 아래 5가지 기준에 따라 평가할 수 있다
  - CPU 이용률
  - 처리량
  - 총 처리 시간
  - 대기 시간
  - 응답 시간
- 선입 선처리(FCFS) 스케줄링은 가장 간단한 스케줄링 알고리즘이지만 짧은 프로세스가 매우 긴 프로세스를 기다리게 할 수 있다
- 최단 작업 우선(short-job-first, SJF) 스케줄링은 최적이며 평균댇기 시간이 가장 짧다
  - 그러나 다음 CPU 버스트의 길이를 예측하기 어려우므로 SJF 스케줄링을 구현하는 것은 어렵다
- 라운드 로빈(RR) 스케줄링은 CPU를 시간 할당량 동안 프로세스에 할당한다
  - 프로세스가 시간 할당량이 만료되기 전에 CPU를 포기하지 않으면 프로세스가 선점되고 다른 프로세스가 시간 할당량 동안 실행되도록 스케줄 된다
- 우선순위 스케줄링은 각 프로세스에 우선순위를 배정하고 CPU는 우선순위가 가장 높은 프로세스에 할당된다
  - 우선순위가 동일한 프로세스는 FCFS 순서로 또는 RR 스케줄링을 사용하여 스케줄 할 수 있다
- 다단계(Multilevel) 큐 스케줄링은 프로세스를 우선순위에 따라 여러 개의 큐로 분할하고 스케줄러는 우선순위가 가장 높은 큐에서 프로세스를 실행한다
  - 큐마다 다른 스케줄링 알고리즘이 사용될 수 있다
- 다단계(Multilevel) 피드백 큐는 프로세스가 다른 큐간에 이주될 수 있다는 점을 제외하고 다단계 큐와 유사하다
- 다중 코어 프로세서는 하나 이상의 CPU를 동일한 물리적 칩에 배치하며 각 CPU에는 둘 이상의 하드웨어 스레드가 있을 수 있다(하이퍼스레딩)
  - 운영체제의 관점에서 보면 각 하드웨어 스레드는 논리적 CPU 처럼 보인다
- 다중 코어 시스템의 부하 균등화(load balancing)는 CPU 코어 간의 부하를 균등하게 만들지만 부하 균등화를 위해 코어 간에 스레드를 이주하면 캐시 내용이 무효가 되어 메모리 액세스 시간이 늘어날 수 있다
- 연성(Soft) 실시간 스케줄링은 비실시간 작업보다 실시간 작업에 우선순위를 둔다
  - 경성(Hard) 실시간 스케줄링은 실시간 작업에 대한 타이밍 보장을 제공한다
- Rate-monotonic 실시간 스케줄링은 선점과 함께 정적 우선순위 정책을 사용하여 주기적 작업을 스케줄 한다
- EDF(earliest deadline first) 스케줄링은 마감시한에 따라 우선순위를 지정한다.
  - 마감시간이 빠를수록 우선순위가 높고, 마감시한이 늦을수록 우선순위가 낮다
- 비례 공유 스케줄은 모든 응용 프로그램이 몫 T를 공유한다
  - 응용 프로그램에 N 몫 만큼의 시간이 배정되면 총 프로세서 시간의 N/T가 보장된다
- Linux는 완벽한 공정 스케줄러(CFS)를 사용하여 각 작업에 일정 비율의 CPU 처리 시간을 할당한다
  - 비율은 각 작업과 관련된 가상 실행시간(vruntime) 값을 기준으로 한다
- Windows 스케줄링은 선점적인 32단계 우선순위 기법을 사용하여 스레드 스케줄링 순서를 결정한다
- Solaris는 전역 우선순위에 매핑된 6개의 고유한 스케줄링 클래스를 식별한다
- CPU를 많이 사용하는 스레드에는 일반적으로 낮은 우선순위(및 더 긴 시간 할당량)가 할당되고 I/O 중심 스레드에는 일반적으로 높은 우선순위(더 짧은 시간 할당량)가 할당된다
- 모델링 및 시뮬레이션을 사용하여 CPU 스케줄링 알고리즘을 평가할 수 있다
